{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d70fc4-8cb6-48ce-838d-16818fea424e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _C: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:416\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[0;32m    415\u001b[0m         _load_global_deps()\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSymInt\u001b[39;00m:\n\u001b[0;32m    420\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _C: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------\n",
    "# 1. Simple CNN Model\n",
    "# -------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # 28x28 -> 24x24\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # 12x12 -> 8x8\n",
    "        self.fc1 = nn.Linear(20 * 4 * 4, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))  # 24x24 -> 12x12\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))  # 8x8 -> 4x4\n",
    "        x = x.view(-1, 20*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Data Partitioning among K clients\n",
    "# -----------------------------------\n",
    "\n",
    "def iid_partition(dataset, num_clients):\n",
    "    \"\"\"\n",
    "    Split the dataset into IID partitions for each client\n",
    "    \"\"\"\n",
    "    num_items = int(len(dataset)/num_clients)\n",
    "    all_indices = [i for i in range(len(dataset))]\n",
    "    client_dict = {}\n",
    "    for i in range(num_clients):\n",
    "        client_dict[i] = set(np.random.choice(all_indices, num_items, replace=False))\n",
    "        all_indices = list(set(all_indices) - client_dict[i])\n",
    "    return client_dict\n",
    "\n",
    "def noniid_partition(dataset, num_clients, num_shards=200, shards_per_client=2):\n",
    "    \"\"\"\n",
    "    Non-IID partitioning based on shard allocation.\n",
    "    MNIST is sorted by labels, split into shards, and each client gets shards.\n",
    "    \"\"\"\n",
    "    idxs = np.arange(len(dataset))\n",
    "    labels = np.array(dataset.targets)\n",
    "    # Sort by label\n",
    "    idxs_labels = np.vstack((idxs, labels))\n",
    "    idxs_labels = idxs_labels[:, idxs_labels[1,:].argsort()]\n",
    "    idxs = idxs_labels[0,:]\n",
    "   \n",
    "    shard_size = int(len(dataset)/num_shards)\n",
    "    shards = [set(idxs[i*shard_size:(i+1)*shard_size]) for i in range(num_shards)]\n",
    "   \n",
    "    client_dict = {i: set() for i in range(num_clients)}\n",
    "    shard_indices = np.arange(num_shards)\n",
    "    np.random.shuffle(shard_indices)\n",
    "    for i in range(num_clients):\n",
    "        assigned_shards = shard_indices[i*shards_per_client:(i+1)*shards_per_client]\n",
    "        for shard_id in assigned_shards:\n",
    "            client_dict[i] = client_dict[i].union(shards[shard_id])\n",
    "    return client_dict\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Client update (local training)\n",
    "# -------------------------------\n",
    "def client_update(client_model, optimizer, train_loader, epochs, device):\n",
    "    \"\"\"\n",
    "    Run local training for a client\n",
    "    \"\"\"\n",
    "    client_model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return client_model.state_dict()\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Server aggregation (FedAvg)\n",
    "# -------------------------------\n",
    "def fed_avg(weights, client_sizes):\n",
    "    \"\"\"\n",
    "    Aggregate client models weighted by the number of samples per client\n",
    "    \"\"\"\n",
    "    total_samples = sum(client_sizes)\n",
    "    avg_weights = copy.deepcopy(weights[0])\n",
    "    for key in avg_weights.keys():\n",
    "        avg_weights[key] = torch.zeros_like(avg_weights[key])\n",
    "    for client_idx, client_weight in enumerate(weights):\n",
    "        for key in avg_weights.keys():\n",
    "            avg_weights[key] += (client_sizes[client_idx] / total_samples) * client_weight[key]\n",
    "    return avg_weights\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Testing the model accuracy\n",
    "# -------------------------------\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return test_loss / total, correct / total\n",
    "\n",
    "# --------------------------------------\n",
    "# 6. Main Federated Training Loop\n",
    "# --------------------------------------\n",
    "def federated_training(\n",
    "    num_clients=10, local_epochs=5, batch_size=32, lr=0.01,\n",
    "    rounds=30, fraction=1.0, iid=True, device='cpu'\n",
    "):\n",
    "    # Load dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # Partition data\n",
    "    if iid:\n",
    "        client_dict = iid_partition(train_dataset, num_clients)\n",
    "    else:\n",
    "        # For non-IID, number of shards and shards_per_client must be set accordingly\n",
    "        shards_per_client = 2\n",
    "        num_shards = num_clients * shards_per_client\n",
    "        client_dict = noniid_partition(train_dataset, num_clients, num_shards=num_shards, shards_per_client=shards_per_client)\n",
    "\n",
    "    # Prepare dataloaders per client\n",
    "    client_loaders = []\n",
    "    client_sizes = []\n",
    "    for i in range(num_clients):\n",
    "        idxs = list(client_dict[i])\n",
    "        client_sizes.append(len(idxs))\n",
    "        subset = Subset(train_dataset, idxs)\n",
    "        loader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "        client_loaders.append(loader)\n",
    "\n",
    "    # Initialize global model\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    global_weights = global_model.state_dict()\n",
    "\n",
    "    # Tracking metrics\n",
    "    global_acc = []\n",
    "    global_loss = []\n",
    "\n",
    "    for r in range(rounds):\n",
    "        print(f\"Round {r+1}/{rounds}\")\n",
    "        m = max(int(fraction * num_clients), 1)\n",
    "        selected_clients = np.random.choice(range(num_clients), m, replace=False)\n",
    "        local_weights = []\n",
    "        local_sizes = []\n",
    "\n",
    "        for client_idx in selected_clients:\n",
    "            # Local model copy\n",
    "            local_model = SimpleCNN().to(device)\n",
    "            local_model.load_state_dict(global_weights)\n",
    "\n",
    "            optimizer = optim.SGD(local_model.parameters(), lr=lr)\n",
    "            local_data_loader = client_loaders[client_idx]\n",
    "\n",
    "            w = client_update(local_model, optimizer, local_data_loader, local_epochs, device)\n",
    "            local_weights.append(w)\n",
    "            local_sizes.append(client_sizes[client_idx])\n",
    "\n",
    "        # Aggregate local weights to update global model\n",
    "        global_weights = fed_avg(local_weights, local_sizes)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        # Evaluate global model\n",
    "        test_loss, test_accuracy = test(global_model, test_loader, device)\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "        global_acc.append(test_accuracy)\n",
    "        global_loss.append(test_loss)\n",
    "\n",
    "    return global_acc, global_loss, global_model\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Centralized SGD training for comparison\n",
    "# ------------------------------\n",
    "def centralized_sgd_train(local_epochs=5, batch_size=32, lr=0.01, rounds=30, device='cpu'):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = SimpleCNN().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    acc = []\n",
    "    loss_list = []\n",
    "\n",
    "    for r in range(rounds):\n",
    "        model.train()\n",
    "        for epoch in range(local_epochs):\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "       \n",
    "        # Test\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, target)\n",
    "                test_loss += loss.item() * data.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        avg_loss = test_loss / total\n",
    "        accuracy = correct / total\n",
    "        print(f\"Round {r+1}, Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy*100:.2f}%\")\n",
    "        acc.append(accuracy)\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "    return acc, loss_list, model\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 8. Run Experiments and Plot Results\n",
    "# ------------------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Running Federated Learning experiments on device:\", device)\n",
    "\n",
    "    # Parameters\n",
    "    num_clients = 10\n",
    "    local_epochs = 5\n",
    "    batch_size = 32\n",
    "    lr = 0.01\n",
    "    rounds = 30\n",
    "    fraction = 1.0  # Use all clients every round\n",
    "\n",
    "    # IID FedAvg\n",
    "    print(\"=== IID FedAvg Training ===\")\n",
    "    fedacc_iid, fedloss_iid, fed_model_iid = federated_training(\n",
    "        num_clients=num_clients, local_epochs=local_epochs, batch_size=batch_size,\n",
    "        lr=lr, rounds=rounds, fraction=fraction, iid=True, device=device\n",
    "    )\n",
    "\n",
    "    # Non-IID FedAvg\n",
    "    print(\"=== Non-IID FedAvg Training ===\")\n",
    "    fedacc_noniid, fedloss_noniid, fed_model_noniid = federated_training(\n",
    "        num_clients=num_clients, local_epochs=local_epochs, batch_size=batch_size,\n",
    "        lr=lr, rounds=rounds, fraction=fraction, iid=False, device=device\n",
    "    )\n",
    "\n",
    "    # Centralized SGD (L=local_epochs)\n",
    "    print(\"=== Centralized SGD Training ===\")\n",
    "    sgd_acc, sgd_loss, sgd_model = centralized_sgd_train(\n",
    "        local_epochs=local_epochs, batch_size=batch_size, lr=lr, rounds=rounds, device=device\n",
    "    )\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(fedacc_iid, label=\"FedAvg IID\")\n",
    "    plt.plot(fedacc_noniid, label=\"FedAvg Non-IID\")\n",
    "    plt.plot(sgd_acc, label=\"Centralized SGD\")\n",
    "    plt.title(\"Test Accuracy over Rounds\")\n",
    "    plt.xlabel(\"Rounds\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(fedloss_iid, label=\"FedAvg IID\")\n",
    "    plt.plot(fedloss_noniid, label=\"FedAvg Non-IID\")\n",
    "    plt.plot(sgd_loss, label=\"Centralized SGD\")\n",
    "    plt.title(\"Test Loss over Rounds\")\n",
    "    plt.xlabel(\"Rounds\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f939055e-ae22-43ad-b7bf-c2bd663166ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp311-cp311-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.8.0-cp311-cp311-win_amd64.whl (241.4 MB)\n",
      "   ---------------------------------------- 0.0/241.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/241.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/241.4 MB 5.0 MB/s eta 0:00:48\n",
      "   ---------------------------------------- 1.8/241.4 MB 4.6 MB/s eta 0:00:53\n",
      "   ---------------------------------------- 2.4/241.4 MB 4.1 MB/s eta 0:00:59\n",
      "   ---------------------------------------- 2.6/241.4 MB 3.2 MB/s eta 0:01:15\n",
      "    --------------------------------------- 4.7/241.4 MB 4.4 MB/s eta 0:00:54\n",
      "   - -------------------------------------- 6.6/241.4 MB 5.2 MB/s eta 0:00:46\n",
      "   - -------------------------------------- 8.4/241.4 MB 5.7 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 10.0/241.4 MB 5.9 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 11.0/241.4 MB 6.0 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 12.6/241.4 MB 6.1 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 13.9/241.4 MB 6.1 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 15.2/241.4 MB 6.2 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 16.5/241.4 MB 6.1 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 17.3/241.4 MB 5.9 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 17.8/241.4 MB 5.8 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 18.6/241.4 MB 5.6 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 19.4/241.4 MB 5.5 MB/s eta 0:00:41\n",
      "   --- ------------------------------------ 20.2/241.4 MB 5.4 MB/s eta 0:00:41\n",
      "   --- ------------------------------------ 21.0/241.4 MB 5.3 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 21.8/241.4 MB 5.3 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 22.8/241.4 MB 5.2 MB/s eta 0:00:43\n",
      "   --- ------------------------------------ 23.6/241.4 MB 5.1 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 24.4/241.4 MB 5.1 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 25.2/241.4 MB 5.0 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 26.0/241.4 MB 5.0 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 27.0/241.4 MB 5.0 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 27.8/241.4 MB 4.9 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 28.6/241.4 MB 4.9 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 29.4/241.4 MB 4.9 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 30.1/241.4 MB 4.9 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 31.2/241.4 MB 4.8 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 32.0/241.4 MB 4.8 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 32.8/241.4 MB 4.8 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 33.8/241.4 MB 4.8 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 34.6/241.4 MB 4.8 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 35.7/241.4 MB 4.8 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 36.4/241.4 MB 4.7 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 37.2/241.4 MB 4.7 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 38.3/241.4 MB 4.7 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 39.1/241.4 MB 4.7 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 40.1/241.4 MB 4.7 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 40.9/241.4 MB 4.7 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 41.7/241.4 MB 4.7 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 42.7/241.4 MB 4.7 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 43.5/241.4 MB 4.6 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 44.3/241.4 MB 4.6 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 45.4/241.4 MB 4.6 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 46.1/241.4 MB 4.6 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 46.9/241.4 MB 4.6 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 48.0/241.4 MB 4.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 48.8/241.4 MB 4.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 49.8/241.4 MB 4.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 50.6/241.4 MB 4.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 51.6/241.4 MB 4.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 52.7/241.4 MB 4.6 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 53.5/241.4 MB 4.6 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 54.5/241.4 MB 4.6 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 55.6/241.4 MB 4.6 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 56.6/241.4 MB 4.6 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 57.7/241.4 MB 4.6 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 58.7/241.4 MB 4.6 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 60.0/241.4 MB 4.6 MB/s eta 0:00:40\n",
      "   ---------- ----------------------------- 61.1/241.4 MB 4.7 MB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 62.1/241.4 MB 4.7 MB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 63.4/241.4 MB 4.7 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 64.7/241.4 MB 4.7 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 66.1/241.4 MB 4.7 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 67.4/241.4 MB 4.7 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 68.7/241.4 MB 4.8 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 70.0/241.4 MB 4.8 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 70.8/241.4 MB 4.8 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 71.8/241.4 MB 4.8 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 72.9/241.4 MB 4.8 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 74.2/241.4 MB 4.8 MB/s eta 0:00:35\n",
      "   ------------ --------------------------- 75.2/241.4 MB 4.8 MB/s eta 0:00:35\n",
      "   ------------ --------------------------- 76.3/241.4 MB 4.8 MB/s eta 0:00:35\n",
      "   ------------ --------------------------- 77.6/241.4 MB 4.8 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 78.9/241.4 MB 4.8 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 80.0/241.4 MB 4.8 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 81.3/241.4 MB 4.8 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 82.3/241.4 MB 4.9 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 83.6/241.4 MB 4.9 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 84.9/241.4 MB 4.9 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 86.5/241.4 MB 4.9 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 87.8/241.4 MB 4.9 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 89.1/241.4 MB 4.9 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 90.4/241.4 MB 5.0 MB/s eta 0:00:31\n",
      "   --------------- ------------------------ 92.0/241.4 MB 5.0 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 93.3/241.4 MB 5.0 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 94.6/241.4 MB 5.0 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 95.9/241.4 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 97.3/241.4 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 98.6/241.4 MB 5.0 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 100.1/241.4 MB 5.1 MB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 101.4/241.4 MB 5.1 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 102.8/241.4 MB 5.1 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 104.3/241.4 MB 5.1 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 105.9/241.4 MB 5.1 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 107.2/241.4 MB 5.1 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 108.5/241.4 MB 5.2 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 109.8/241.4 MB 5.2 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 110.9/241.4 MB 5.2 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.9/241.4 MB 5.2 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 113.0/241.4 MB 5.2 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 114.0/241.4 MB 5.2 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 115.3/241.4 MB 5.2 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 116.4/241.4 MB 5.2 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 117.7/241.4 MB 5.2 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 119.0/241.4 MB 5.2 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 120.3/241.4 MB 5.2 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 121.6/241.4 MB 5.2 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 122.9/241.4 MB 5.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 124.3/241.4 MB 5.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 125.3/241.4 MB 5.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 126.4/241.4 MB 5.2 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 127.7/241.4 MB 5.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 129.0/241.4 MB 5.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 130.3/241.4 MB 5.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 131.6/241.4 MB 5.2 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 132.9/241.4 MB 5.2 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 134.0/241.4 MB 5.2 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 134.7/241.4 MB 5.2 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 135.8/241.4 MB 5.2 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 136.6/241.4 MB 5.2 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 137.6/241.4 MB 5.2 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 138.7/241.4 MB 5.2 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 140.0/241.4 MB 5.2 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 141.0/241.4 MB 5.2 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 142.3/241.4 MB 5.2 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 143.4/241.4 MB 5.2 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 144.4/241.4 MB 5.2 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 145.5/241.4 MB 5.2 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 146.8/241.4 MB 5.2 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 147.8/241.4 MB 5.2 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 149.2/241.4 MB 5.2 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 150.5/241.4 MB 5.2 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 151.5/241.4 MB 5.2 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 152.8/241.4 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 153.9/241.4 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 154.9/241.4 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 156.0/241.4 MB 5.2 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 157.3/241.4 MB 5.2 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 158.3/241.4 MB 5.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 159.4/241.4 MB 5.3 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 160.4/241.4 MB 5.3 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 161.7/241.4 MB 5.3 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 162.8/241.4 MB 5.3 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 164.1/241.4 MB 5.3 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 165.2/241.4 MB 5.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 165.9/241.4 MB 5.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 167.0/241.4 MB 5.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 167.8/241.4 MB 5.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 168.8/241.4 MB 5.2 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 169.6/241.4 MB 5.1 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 170.7/241.4 MB 5.1 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 171.7/241.4 MB 5.1 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 172.8/241.4 MB 5.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 173.8/241.4 MB 5.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 174.9/241.4 MB 5.2 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 175.9/241.4 MB 5.2 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 177.2/241.4 MB 5.2 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 178.3/241.4 MB 5.2 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 179.3/241.4 MB 5.2 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 180.4/241.4 MB 5.2 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 181.4/241.4 MB 5.2 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 182.7/241.4 MB 5.2 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 183.8/241.4 MB 5.3 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 184.8/241.4 MB 5.3 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 185.9/241.4 MB 5.3 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 186.9/241.4 MB 5.3 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 188.2/241.4 MB 5.3 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 189.3/241.4 MB 5.3 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 190.3/241.4 MB 5.3 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 191.4/241.4 MB 5.3 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 192.7/241.4 MB 5.3 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 193.7/241.4 MB 5.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 194.8/241.4 MB 5.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 195.6/241.4 MB 5.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 196.3/241.4 MB 5.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 197.4/241.4 MB 5.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 198.2/241.4 MB 5.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 199.0/241.4 MB 5.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 199.8/241.4 MB 5.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 200.3/241.4 MB 5.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 200.8/241.4 MB 5.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 201.1/241.4 MB 5.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 201.6/241.4 MB 5.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 201.9/241.4 MB 5.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 202.4/241.4 MB 5.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 202.9/241.4 MB 5.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 203.4/241.4 MB 5.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 203.9/241.4 MB 5.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 204.5/241.4 MB 5.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 205.0/241.4 MB 5.1 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 205.5/241.4 MB 5.1 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 205.8/241.4 MB 5.1 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 206.3/241.4 MB 5.1 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 206.8/241.4 MB 5.1 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 207.4/241.4 MB 5.1 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 207.9/241.4 MB 5.1 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 208.7/241.4 MB 5.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 209.2/241.4 MB 5.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 209.2/241.4 MB 5.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 209.7/241.4 MB 5.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 210.2/241.4 MB 4.9 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 210.8/241.4 MB 4.9 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 211.3/241.4 MB 4.9 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 211.8/241.4 MB 4.9 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 212.1/241.4 MB 4.8 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 212.6/241.4 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 213.4/241.4 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 213.9/241.4 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 214.4/241.4 MB 4.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 215.0/241.4 MB 4.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 215.5/241.4 MB 4.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 216.0/241.4 MB 4.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 216.5/241.4 MB 4.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 217.3/241.4 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 217.8/241.4 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 218.4/241.4 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 218.9/241.4 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 219.4/241.4 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 219.9/241.4 MB 4.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 220.7/241.4 MB 4.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 221.2/241.4 MB 4.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 221.8/241.4 MB 4.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 222.3/241.4 MB 4.4 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 223.1/241.4 MB 4.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 223.6/241.4 MB 4.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 224.1/241.4 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 224.7/241.4 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 225.2/241.4 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 225.7/241.4 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 226.2/241.4 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 227.0/241.4 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 227.5/241.4 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 228.1/241.4 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 228.9/241.4 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 229.4/241.4 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 230.2/241.4 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 230.7/241.4 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 231.2/241.4 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 232.0/241.4 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 232.5/241.4 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 233.3/241.4 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 234.1/241.4 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 234.6/241.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  235.4/241.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  236.2/241.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  237.0/241.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  237.8/241.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  238.3/241.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  238.8/241.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  239.6/241.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  240.1/241.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  240.6/241.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.4/241.4 MB 3.7 MB/s  0:00:54\n",
      "Downloading torchvision-0.23.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.4 MB/s  0:00:00\n",
      "Installing collected packages: torch, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Luv Mathur\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\torch\\\\lib\\\\asmjit.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d846686-0d70-4053-a686-a56cf66ae737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\luv mathur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/b7/3f/945ef7ab14dc4f9d7f40288d2df998d1837ee0888ec3659c813487572faa/pip-25.2-py3-none-any.whl.metadata\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.1/1.8 MB 812.7 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.4/1.8 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.2/1.8 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.5/1.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-25.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5a7df-f2a2-4593-bf4f-b54c35d45f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
